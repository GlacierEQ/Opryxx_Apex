version: '3.8'

services:
  app:
    build:
      context: .
      target: development
    command: uvicorn ai_workbench.api.app:create_app --host 0.0.0.0 --port 8000 --reload
    volumes:
      - .:/app
      - /app/venv
      - /app/__pycache__
      - /app/.pytest_cache
    environment:
      - ENVIRONMENT=development
      - LOG_LEVEL=DEBUG
      - RELOAD=true
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"

  postgres:
    image: postgres:15-alpine
    container_name: opryxx-postgres
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=opryxx
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/initdb.d:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: opryxx-redis
    command: redis-server --requirepass ${REDIS_PASSWORD:-}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: opryxx-pgadmin
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@opryxx.ai
      - PGADMIN_DEFAULT_PASSWORD=admin
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    ports:
      - "5050:80"
    depends_on:
      - postgres

  prometheus:
    image: prom/prometheus:latest
    container_name: opryxx-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    volumes:
      - ./prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: opryxx-grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource,grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    ports:
      - "3000:3000"
    restart: unless-stopped

  loki:
    image: grafana/loki:latest
    container_name: opryxx-loki
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - loki_data:/loki
    restart: unless-stopped

  promtail:
    image: grafana/promtail:latest
    container_name: opryxx-promtail
    volumes:
      - ./logs:/var/log/opryxx
      - ./promtail:/etc/promtail
    command: -config.file=/etc/promtail/config.yml
    restart: unless-stopped
    depends_on:
      - loki

  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: opryxx-jaeger
    ports:
      - "16686:16686"
      - "4317:4317"
      - "4318:4318"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    restart: unless-stopped

  tempo:
    image: grafana/tempo:latest
    container_name: opryxx-tempo
    command: ["-config.file=/etc/tempo.yaml"]
    volumes:
      - ./tempo:/etc/tempo
      - tempo_data:/tmp/tempo
    ports:
      - "3200:3200"   # tempo
      - "4317:4317"   # otlp grpc
      - "4318:4318"   # otlp http
      - "9411:9411"   # zipkin
    restart: unless-stopped

  node-exporter:
    image: prom/node-exporter:latest
    container_name: opryxx-node-exporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    ports:
      - "9100:9100"
    restart: unless-stopped

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: opryxx-cadvisor
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    ports:
      - "8080:8080"
    restart: unless-stopped
    privileged: true
    devices:
      - /dev/kmsg:/dev/kmsg

  portainer:
    image: portainer/portainer-ce:latest
    container_name: opryxx-portainer
    command: -H unix:///var/run/docker.sock
    restart: always
    ports:
      - "9000:9000"
      - "8000:8000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data

  mailhog:
    image: mailhog/mailhog:latest
    container_name: opryxx-mailhog
    ports:
      - "1025:1025" # SMTP server
      - "8025:8025" # Web UI
    restart: unless-stopped

  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: opryxx-redis-commander
    environment:
      - REDIS_HOSTS=local:redis:6379
    ports:
      - "8081:8081"
    depends_on:
      - redis
    restart: unless-stopped

  flower:
    image: mher/flower:1.0.0
    container_name: opryxx-flower
    command: --broker=redis://:${REDIS_PASSWORD}@redis:6379/0
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/0
    depends_on:
      - redis
    restart: unless-stopped

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.7.0
    container_name: opryxx-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:8.7.0
    container_name: opryxx-kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    restart: unless-stopped

  minio:
    image: minio/minio:latest
    container_name: opryxx-minio
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    restart: unless-stopped

  mongo:
    image: mongo:6.0
    container_name: opryxx-mongo
    environment:
      - MONGO_INITDB_ROOT_USERNAME=root
      - MONGO_INITDB_ROOT_PASSWORD=example
      - MONGO_INITDB_DATABASE=opryxx
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "'db.runCommand({ ping: 1 })'"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  mongo-express:
    image: mongo-express:latest
    container_name: opryxx-mongo-express
    environment:
      - ME_CONFIG_MONGODB_SERVER=mongo
      - ME_CONFIG_MONGODB_ADMINUSERNAME=root
      - ME_CONFIG_MONGODB_ADMINPASSWORD=example
      - ME_CONFIG_BASICAUTH_USERNAME=admin
      - ME_CONFIG_BASICAUTH_PASSWORD=admin
    ports:
      - "8082:8081"
    depends_on:
      - mongo
    restart: unless-stopped

  rabbitmq:
    image: rabbitmq:3.11-management
    container_name: opryxx-rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=guest
      - RABBITMQ_DEFAULT_PASS=guest
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_port_connectivity"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  traefik:
    image: traefik:v2.10
    container_name: opryxx-traefik
    command:
      - --api.insecure=true
      - --providers.docker=true
      - --providers.docker.exposedbydefault=false
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --certificatesresolvers.myresolver.acme.tlschallenge=true
      - --certificatesresolvers.myresolver.acme.email=admin@opryxx.ai
      - --certificatesresolvers.myresolver.acme.storage=/letsencrypt/acme.json
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./letsencrypt:/letsencrypt
    restart: unless-stopped

  whoami:
    image: containous/whoami
    container_name: opryxx-whoami
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.whoami.rule=Host(`whoami.localhost`)"
      - "traefik.http.routers.whoami.entrypoints=web"
    restart: unless-stopped

  swagger-editor:
    image: swaggerapi/swagger-editor
    container_name: opryxx-swagger-editor
    ports:
      - "8083:8080"
    restart: unless-stopped

  swagger-ui:
    image: swaggerapi/swagger-ui
    container_name: opryxx-swagger-ui
    ports:
      - "8084:8080"
    environment:
      - URLS=[{url: "/swagger.json", name: "OPRYXX API"}]
    volumes:
      - ./docs/swagger.json:/usr/share/nginx/html/swagger.json
    restart: unless-stopped

  redisinsight:
    image: redislabs/redisinsight:latest
    container_name: opryxx-redisinsight
    volumes:
      - redisinsight_data:/db
    ports:
      - "8001:8001"
    restart: unless-stopped
    depends_on:
      - redis

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: opryxx-mlflow
    environment:
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - MLFLOW_S3_IGNORE_TLS=true
    command: >
      mlflow server
      --backend-store-uri postgresql://postgres:postgres@postgres:5432/mlflow
      --default-artifact-root s3://mlflow/
      --host 0.0.0.0
      --port 5000
    ports:
      - "5000:5000"
    depends_on:
      - postgres
      - minio
    restart: unless-stopped

  jupyter:
    image: jupyter/scipy-notebook:latest
    container_name: opryxx-jupyter
    environment:
      - JUPYTER_TOKEN=opryxx123
      - GRANT_SUDO=yes
    volumes:
      - ./notebooks:/home/jovyan/work
    ports:
      - "8888:8888"
    restart: unless-stopped

  airflow:
    image: apache/airflow:2.7.0
    container_name: opryxx-airflow
    depends_on:
      - postgres
      - redis
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=''
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION='true'
      - AIRFLOW__CORE__LOAD_EXAMPLES='false'
      - AIRFLOW__API__AUTH_BACKEND='airflow.api.auth.backend.basic_auth'
      - _PIP_ADDITIONAL_PACKAGES='apache-airflow-providers-postgres apache-airflow-providers-redis apache-airflow-providers-celery'
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    ports:
      - "8085:8080"
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3
    restart: unless-stopped

  airflow-scheduler:
    image: apache/airflow:2.7.0
    container_name: opryxx-airflow-scheduler
    command: scheduler
    depends_on:
      - airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=''
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION='true'
      - AIRFLOW__CORE__LOAD_EXAMPLES='false'
      - _PIP_ADDITIONAL_PACKAGES='apache-airflow-providers-postgres apache-airflow-providers-redis apache-airflow-providers-celery'
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    restart: unless-stopped

  airflow-worker:
    image: apache/airflow:2.7.0
    container_name: opryxx-airflow-worker
    command: celery worker
    depends_on:
      - airflow
      - airflow-scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=''
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION='true'
      - AIRFLOW__CORE__LOAD_EXAMPLES='false'
      - _PIP_ADDITIONAL_PACKAGES='apache-airflow-providers-postgres apache-airflow-providers-redis apache-airflow-providers-celery'
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    restart: unless-stopped

  airflow-flower:
    image: apache/airflow:2.7.0
    container_name: opryxx-airflow-flower
    command: celery flower
    ports:
      - "5555:5555"
    depends_on:
      - airflow
      - airflow-scheduler
      - airflow-worker
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=''
      - _PIP_ADDITIONAL_PACKAGES='apache-airflow-providers-postgres apache-airflow-providers-redis apache-airflow-providers-celery'
    restart: unless-stopped

  airflow-init:
    image: apache/airflow:2.7.0
    container_name: opryxx-airflow-init
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=''
      - _PIP_ADDITIONAL_PACKAGES='apache-airflow-providers-postgres apache-airflow-providers-redis apache-airflow-providers-celery'
    command: >
      bash -c '
      airflow db init && \
      airflow users create \
        --username admin \
        --password admin \
        --firstname Admin \
        --lastname User \
        --role Admin \
        --email admin@example.com || true'
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    restart: on-failure

volumes:
  postgres_data:
  redis_data:
  pgadmin_data:
  prometheus_data:
  grafana_data:
  loki_data:
  tempo_data:
  portainer_data:
  elasticsearch_data:
  minio_data:
  mongo_data:
  rabbitmq_data:
  redisinsight_data:
